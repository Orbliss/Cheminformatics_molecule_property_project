{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0fd442c",
   "metadata": {},
   "source": [
    "# Data importation and evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666209e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Helper function to combine ECFP and SMILES datasets\n",
    "def dataset_to_df_with_smiles(ecfp_dataset, raw_dataset, tasks):\n",
    "    X_list, y_list, ids_list, smiles_list = [], [], [], []\n",
    "    \n",
    "    # Iterate through both datasets in parallel\n",
    "    for (X_batch, y_batch, w_batch, ids_batch), (X_raw, _, _, _) in zip(\n",
    "        ecfp_dataset.iterbatches(batch_size=128, pad_batches=False),\n",
    "        raw_dataset.iterbatches(batch_size=128, pad_batches=False)\n",
    "    ):\n",
    "        X_list.append(X_batch)\n",
    "        y_list.append(y_batch)\n",
    "        ids_list.extend(ids_batch)\n",
    "        smiles_list.extend(X_raw)  # SMILES strings are in the raw features\n",
    "\n",
    "    # Stack numerical and label arrays\n",
    "    X_all = np.vstack(X_list)\n",
    "    y_all = np.vstack(y_list)\n",
    "\n",
    "    # Create DataFrames\n",
    "    df_X = pd.DataFrame(X_all, columns=[f\"fp_{i}\" for i in range(X_all.shape[1])])\n",
    "    df_y = pd.DataFrame(y_all, columns=tasks)\n",
    "    df_y[\"mol_id\"] = ids_list\n",
    "    df_y[\"smiles\"] = smiles_list\n",
    "\n",
    "    # Combine all information into a single DataFrame\n",
    "    df = pd.concat([df_y, df_X], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load SIDER dataset with ECFP features (for model input)\n",
    "tasks, datasets, transformers = dc.molnet.load_sider(featurizer='ECFP', splitter='scaffold')\n",
    "train_ecfp, valid_ecfp, test_ecfp = datasets\n",
    "\n",
    "# Load SIDER dataset again with raw SMILES (for visualization / metadata)\n",
    "_, datasets_raw, _ = dc.molnet.load_sider(featurizer='Raw', splitter='scaffold')\n",
    "train_raw, valid_raw, test_raw = datasets_raw\n",
    "\n",
    "# Convert both representations to DataFrames\n",
    "df_train = dataset_to_df_with_smiles(train_ecfp, train_raw, tasks)\n",
    "df_valid = dataset_to_df_with_smiles(valid_ecfp, valid_raw, tasks)\n",
    "df_test  = dataset_to_df_with_smiles(test_ecfp,  test_raw,  tasks)\n",
    "\n",
    "feature_cols = [col for col in df_train.columns if col.startswith(\"fp_\")]\n",
    "label_cols = [col for col in df_train.columns if col not in feature_cols + ['mol_id', 'smiles', 'scaffold']]\n",
    "\n",
    "X_train = df_train[feature_cols].astype(float).values\n",
    "y_train = df_train[label_cols].astype(float).values\n",
    "\n",
    "X_valid = df_valid[feature_cols].astype(float).values\n",
    "y_valid = df_valid[label_cols].astype(float).values\n",
    "\n",
    "X_test = df_test[feature_cols].astype(float).values\n",
    "y_test = df_test[label_cols].astype(float).values\n",
    "\n",
    "pca = PCA().fit(X_train)\n",
    "cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Number of components to reach 80% variance\n",
    "n_components_80 = np.argmax(cumulative_variance >= 0.80) + 1\n",
    "\n",
    "pca = PCA(n_components=n_components_80)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_valid_pca = pca.transform(X_valid)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, hamming_loss, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "def evaluate_multilabel_model(y_true, y_pred, y_prob=None, name=None):\n",
    "    \"\"\"\n",
    "    Evaluate multilabel classification performance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        Ground-truth binary matrix (n_samples x n_labels)\n",
    "    y_pred : np.ndarray\n",
    "        Predicted binary matrix (same shape as y_true)\n",
    "    y_prob : np.ndarray, optional\n",
    "        Predicted probabilities (for ROC-AUC if available)\n",
    "    name : str\n",
    "        Name of the dataframe evaluated\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {\"Nom :\": name}\n",
    "    metrics[\"Subset accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    metrics[\"Hamming loss\"] = hamming_loss(y_true, y_pred)\n",
    "    metrics[\"Micro F1\"] = f1_score(y_true, y_pred, average=\"micro\")\n",
    "    metrics[\"Macro F1\"] = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    metrics[\"Weighted F1\"] = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    \n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            metrics[\"Micro ROC-AUC\"] = roc_auc_score(y_true, y_prob, average=\"micro\")\n",
    "            metrics[\"Macro ROC-AUC\"] = roc_auc_score(y_true, y_prob, average=\"macro\")\n",
    "        except ValueError:\n",
    "            metrics[\"Micro ROC-AUC\"] = np.nan\n",
    "            metrics[\"Macro ROC-AUC\"] = np.nan\n",
    "\n",
    "    print(\"\\n📊 Multilabel Evaluation Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"{k:20s}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k:20s}: {v}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5279b1",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Radom Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f8d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest on PCA-reduced Data ===\n",
      "\n",
      "📊 Multilabel Evaluation Metrics:\n",
      "Nom :               : Train (RF)\n",
      "Subset accuracy     : 0.9947\n",
      "Hamming loss        : 0.0007\n",
      "Micro F1            : 0.9994\n",
      "Macro F1            : 0.9994\n",
      "Weighted F1         : 0.9994\n",
      "Micro ROC-AUC       : 1.0000\n",
      "Macro ROC-AUC       : 1.0000\n",
      "\n",
      "📊 Multilabel Evaluation Metrics:\n",
      "Nom :               : Validation (RF)\n",
      "Subset accuracy     : 0.0280\n",
      "Hamming loss        : 0.2077\n",
      "Micro F1            : 0.8408\n",
      "Macro F1            : 0.6354\n",
      "Weighted F1         : 0.8109\n",
      "Micro ROC-AUC       : 0.8454\n",
      "Macro ROC-AUC       : 0.6124\n",
      "\n",
      "📊 Multilabel Evaluation Metrics:\n",
      "Nom :               : Test (RF)\n",
      "Subset accuracy     : 0.0140\n",
      "Hamming loss        : 0.2274\n",
      "Micro F1            : 0.8190\n",
      "Macro F1            : 0.6235\n",
      "Weighted F1         : 0.8011\n",
      "Micro ROC-AUC       : 0.8438\n",
      "Macro ROC-AUC       : 0.6063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Nom :': 'Test (RF)',\n",
       " 'Subset accuracy': 0.013986013986013986,\n",
       " 'Hamming loss': 0.2274022274022274,\n",
       " 'Micro F1': 0.8189690721649484,\n",
       " 'Macro F1': 0.6235109554733006,\n",
       " 'Weighted F1': 0.8010790941806424,\n",
       " 'Micro ROC-AUC': 0.8438092496275152,\n",
       " 'Macro ROC-AUC': 0.6063287065050921}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Random Forest multi-label\n",
    "rf_model = OneVsRestClassifier(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=200,       \n",
    "        max_depth=30,         \n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train\n",
    "rf_model.fit(X_train_pca, y_train)\n",
    "\n",
    "\n",
    "y_train_pred_rf_pca = rf_model.predict(X_train_pca)\n",
    "y_valid_pred_rf_pca = rf_model.predict(X_valid_pca)\n",
    "y_test_pred_rf_pca = rf_model.predict(X_test_pca)\n",
    "\n",
    "y_train_prob_rf_pca = rf_model.predict_proba(X_train_pca)\n",
    "y_valid_prob_rf_pca = rf_model.predict_proba(X_valid_pca)\n",
    "y_test_prob_rf_pca = rf_model.predict_proba(X_test_pca)\n",
    "\n",
    "print(\"=== Random Forest on PCA-reduced Data ===\")\n",
    "evaluate_multilabel_model(y_train, y_train_pred_rf_pca, y_train_prob_rf_pca, \"Train (RF)\")\n",
    "evaluate_multilabel_model(y_valid, y_valid_pred_rf_pca, y_valid_prob_rf_pca, \"Validation (RF)\")\n",
    "evaluate_multilabel_model(y_test, y_test_pred_rf_pca, y_test_prob_rf_pca, \"Test (RF)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe78bcb",
   "metadata": {},
   "source": [
    "### Random Forest (RF) on PCA Data 🌲\n",
    "**Training:** Massive overfitting (near-perfect scores). The model is memorizing the training data.\n",
    "\n",
    "**Test:**\n",
    "- Micro F1: 0.819 (Moderate performance on frequent labels).\n",
    "- Macro F1: 0.624 (Poor performance on rare labels).\n",
    "- Macro ROC AUC: 0.606 (Poor average discrimination across labels).\n",
    "- Hamming Loss: 0.227 (~23% of labels mispredicted).\n",
    "\n",
    "**RF (on PCA) Conclusion:** The model still overfits heavily, although PCA slightly reduced it compared to an unregularized model. It performs moderately on common labels but fails on rare labels. The improvement over Logistic Regression on PCA is minimal.\n",
    "\n",
    "**Comparison with Initial Logistic Regression (LR) (on raw ECFP)**\n",
    "\n",
    "Initial Logistic Regression (Test):\n",
    "\n",
    "- Micro F1: 0.771\n",
    "- Macro F1: 0.622\n",
    "- Macro ROC AUC: 0.596\n",
    "- Hamming Loss: 0.271\n",
    "\n",
    "Comparison:\n",
    "\n",
    "Overfitting: Both models overfit, but the Random Forest (even on PCA) shows even more extreme overfitting on the training set (perfect scores) than the initial LR.\n",
    "\n",
    "Performance (Common Labels): RF (on PCA) is slightly better on common labels (Micro F1: 0.819 vs 0.771 for LR).\n",
    "\n",
    "Performance (Rare Labels): Neither model performs well on rare labels (Macro F1 around 0.62 for both; Macro ROC AUC around 0.60 for both).\n",
    "\n",
    "Overall Label Errors: RF (on PCA) makes slightly fewer overall label errors (Hamming Loss 0.227 vs 0.271 for LR).\n",
    "\n",
    "Overall Conclusion: The Random Forest (even with PCA and balanced weights) overfits massively and doesn't significantly improve generalization compared to the initial Logistic Regression, especially for rare labels. PCA reduced dimensionality but wasn't sufficient to solve the core generalization challenge related to scaffolds and label imbalance for this more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Lancement de GridSearchCV pour RandomForestClassifier...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Définir l'estimateur de base\n",
    "base_estimator = OneVsRestClassifier(\n",
    "    RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Définir la grille d'hyperparamètres à tester\n",
    "# Le préfixe 'estimator__' est nécessaire pour passer les paramètres\n",
    "# au RandomForestClassifier à l'intérieur de OneVsRestClassifier.\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [100, 200, 300],\n",
    "    'estimator__max_depth': [10, 20, None],\n",
    "    'estimator__min_samples_split': [2, 5],\n",
    "    'estimator__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# 3. Mettre en place GridSearchCV\n",
    "# Le score 'f1_macro' est un bon choix pour les problèmes multi-labels déséquilibrés.\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=base_estimator,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro', # Métrique de score\n",
    "    cv=3,             # Validation croisée à 3 plis\n",
    "    verbose=2,\n",
    "    n_jobs=-1         # Utiliser tous les cœurs disponibles\n",
    ")\n",
    "\n",
    "print(\"🚀 Lancement de GridSearchCV pour RandomForestClassifier...\")\n",
    "# 4. Lancer la recherche sur les données d'entraînement réduites par PCA\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# 5. Afficher les meilleurs paramètres trouvés\n",
    "print(\"\\n✅ Meilleurs paramètres trouvés :\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\n🏆 Meilleur score F1-macro sur les plis de validation : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Utiliser le meilleur estimateur trouvé pour la prédiction finale\n",
    "best_rf_model_grid = grid_search.best_estimator_\n",
    "\n",
    "# Évaluer le meilleur modèle sur l'ensemble de test\n",
    "y_test_pred_best_grid = best_rf_model_grid.predict(X_test_pca)\n",
    "y_test_prob_best_grid = best_rf_model_grid.predict_proba(X_test_pca)\n",
    "print(\"\\n=== Évaluation du meilleur Random Forest (GridSearch) sur l'ensemble de test ===\")\n",
    "evaluate_multilabel_model(y_test, y_test_pred_best_grid, y_test_prob_best_grid, \"Test (Best RF - Grid)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cheminformatics_project)",
   "language": "python",
   "name": "cheminformatics_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
